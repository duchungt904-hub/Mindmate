import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

class GPTService:
    def __init__(self):
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key or api_key == 'your_openai_api_key_here' or 'DEMO' in api_key:
            print("è­¦å‘Šï¼šæœªé…ç½®æœ‰æ•ˆçš„ OPENAI_API_KEYï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®")
        
        # åˆ›å»º OpenAI å®¢æˆ·ç«¯ï¼Œæ”¯æŒè‡ªå®šä¹‰ base_url
        base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        
        # æ ¹æ® base_url è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
        if 'deepseek' in base_url.lower():
            self.model = "deepseek-chat"  # DeepSeek æ¨¡å‹
            print(f"ä½¿ç”¨ DeepSeek æ¨¡å‹: {self.model}")
        else:
            self.model = "gpt-3.5-turbo"  # OpenAI æ¨¡å‹
            print(f"ä½¿ç”¨ OpenAI æ¨¡å‹: {self.model}")
    
    def generate_response(self, user_message, chat_history, system_prompt, user_profile=None):
        """
        ç”Ÿæˆ AI å›å¤
        
        Args:
            user_message: ç”¨æˆ·å½“å‰çš„æ¶ˆæ¯
            chat_history: èŠå¤©å†å²è®°å½•åˆ—è¡¨
            system_prompt: Avatar çš„ç³»ç»Ÿæç¤ºï¼ˆPersonaï¼‰
            user_profile: ç”¨æˆ·èµ„æ–™ï¼ˆå¯é€‰ï¼Œç”¨äºä¸ªæ€§åŒ–ï¼‰
        """
        # æ„å»ºä¸ªæ€§åŒ–çš„ç³»ç»Ÿæç¤º
        enhanced_prompt = system_prompt
        
        if user_profile:
            profile_info = []
            if user_profile.get('name'):
                profile_info.append(f"ç”¨æˆ·çš„åå­—æ˜¯ {user_profile['name']}")
            if user_profile.get('gender'):
                gender_text = {'male': 'ç”·æ€§', 'female': 'å¥³æ€§'}.get(user_profile['gender'], '')
                if gender_text:
                    profile_info.append(f"ç”¨æˆ·æ˜¯{gender_text}")
            if user_profile.get('goal'):
                profile_info.append(f"ç”¨æˆ·çš„åº§å³é“­æ˜¯ï¼š{user_profile['goal']}")
            if user_profile.get('date_birth'):
                profile_info.append(f"ç”¨æˆ·çš„ç”Ÿæ—¥æ˜¯ {user_profile['date_birth']}")
            if user_profile.get('self_description'):
                profile_info.append(f"ç”¨æˆ·è¿™æ ·æè¿°è‡ªå·±ï¼š{user_profile['self_description']}")
            
            if profile_info:
                enhanced_prompt += "\n\nç”¨æˆ·ä¿¡æ¯ï¼š\n" + "\n".join(profile_info)
                enhanced_prompt += "\n\nè¯·åœ¨å¯¹è¯ä¸­é€‚å½“åœ°å‚è€ƒè¿™äº›ä¿¡æ¯ï¼Œè®©å¯¹è¯æ›´åŠ ä¸ªæ€§åŒ–å’Œè´´å¿ƒã€‚"
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            {"role": "system", "content": enhanced_prompt}
        ]
        
        # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆé™åˆ¶æ•°é‡ä»¥é¿å…è¶…å‡º token é™åˆ¶ï¼‰
        max_history = 10
        recent_history = chat_history[-max_history:] if len(chat_history) > max_history else chat_history
        
        for msg in recent_history:
            role = "user" if msg['sender'] == 'user' else "assistant"
            messages.append({"role": role, "content": msg['message']})
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.8,
                max_tokens=500
            )
            
            return {
                "success": True,
                "message": response.choices[0].message.content
            }
        except Exception as e:
            error_msg = str(e)
            print(f"GPT API è°ƒç”¨å¤±è´¥: {error_msg}")
            
            # æä¾›æ›´å‹å¥½çš„é”™è¯¯æç¤º
            if "api_key" in error_msg.lower() or "authentication" in error_msg.lower():
                user_msg = "API å¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"
            elif "rate_limit" in error_msg.lower():
                user_msg = "API è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼Œè¯·ç¨åå†è¯•"
            elif "model" in error_msg.lower():
                user_msg = f"æ¨¡å‹ {self.model} ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®"
            elif "connection" in error_msg.lower() or "timeout" in error_msg.lower():
                user_msg = "ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•"
            else:
                user_msg = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ã€‚"
            
            return {
                "success": False,
                "error": user_msg,
                "message": user_msg  # æ·»åŠ  message å­—æ®µç”¨äºç›´æ¥æ˜¾ç¤º
            }
    
    def analyze_mood_from_text(self, text):
        """
        ä»æ–‡æœ¬ä¸­åˆ†æå¿ƒæƒ…
        è¿”å›ä¸€ä¸ª emoji è¡¨æƒ…
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªæƒ…ç»ªåˆ†æåŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·çš„æ–‡æœ¬å†…å®¹ï¼Œåˆ¤æ–­ç”¨æˆ·çš„æ•´ä½“å¿ƒæƒ…ï¼Œå¹¶è¿”å›ä¸€ä¸ªæœ€åˆé€‚çš„ emoji è¡¨æƒ…ã€‚åªè¿”å›ä¸€ä¸ª emojiï¼Œä¸è¦è¿”å›å…¶ä»–å†…å®¹ã€‚å¯é€‰çš„ emojiï¼šğŸ˜Šï¼ˆå¼€å¿ƒï¼‰ã€ğŸ˜¢ï¼ˆéš¾è¿‡ï¼‰ã€ğŸ˜Œï¼ˆå¹³é™ï¼‰ã€ğŸ˜¤ï¼ˆç”Ÿæ°”ï¼‰ã€ğŸ˜°ï¼ˆç„¦è™‘ï¼‰ã€ğŸ¤”ï¼ˆæ€è€ƒï¼‰ã€ğŸ˜´ï¼ˆç–²æƒ«ï¼‰ã€ğŸ¥³ï¼ˆå…´å¥‹ï¼‰"
                    },
                    {
                        "role": "user",
                        "content": text
                    }
                ],
                temperature=0.3,
                max_tokens=10
            )
            
            emoji = response.choices[0].message.content.strip()
            return emoji
        except Exception as e:
            print(f"å¿ƒæƒ…åˆ†æå¤±è´¥: {str(e)}")
            return "ğŸ˜Š"  # é»˜è®¤è¿”å›å¼€å¿ƒ
